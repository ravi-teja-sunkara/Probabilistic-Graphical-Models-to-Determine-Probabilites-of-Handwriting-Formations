{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.sampling import BayesianModelSampling\n",
    "from pgmpy.estimators import ExhaustiveSearch, K2Score\n",
    "from pgmpy.inference import VariableElimination\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv files\n",
    "t2 = pd.read_csv('./cpd/Table2.csv')\n",
    "t3 = pd.read_csv('./cpd/Table3.csv')\n",
    "t4 = pd.read_csv('./cpd/Table4.csv')\n",
    "t5 = pd.read_csv('./cpd/Table5.csv')\n",
    "t6 = pd.read_csv('./cpd/Table6.csv')\n",
    "t7 = pd.read_csv('./cpd/Table7.csv')\n",
    "t8 = pd.read_csv('./cpd/Table8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the variables columns and saving the numeric values into an array\n",
    "t2.drop(['values'], axis=1, inplace=True)\n",
    "t3.drop(['x1'], axis=1, inplace=True)\n",
    "t4.drop(['x2'], axis=1, inplace=True)\n",
    "t5.drop(['x3'], axis=1, inplace=True)\n",
    "t6.drop(['x4'], axis=1, inplace=True)\n",
    "t7.drop(['x5'], axis=1, inplace=True)\n",
    "t8.drop(['x6'], axis=1, inplace=True)\n",
    "\n",
    "# to numpy arrays\n",
    "t2_array = t2.values\n",
    "t3_array = t3.values\n",
    "t4_array = t4.values\n",
    "t5_array = t5.values\n",
    "t6_array = t6.values\n",
    "t7_array = t7.values\n",
    "t8_array = t8.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Finding Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation between x1 and x2\n",
      "0.1598\n",
      "correlation between x1 and x4\n",
      "0.1194\n",
      "correlation between x1 and x6\n",
      "0.1602\n"
     ]
    }
   ],
   "source": [
    "# Correlation of x1 with other features\n",
    "t3_corr= np.zeros((t3.shape[0]-1,t3.shape[1]))\n",
    "corr_x1x2 = 0 \n",
    "corr_x1x4 = 0\n",
    "corr_x1x6 = 0\n",
    "for i in range(0,len(t2_array)):\n",
    "    for j in range(len(t3_array[0])):\n",
    "            t3_corr[i][j]= abs(t3_array[i+1][j]-t2_array[i][1])\n",
    "            \n",
    "k =i\n",
    "for i in range(0,len(t2_array)-1):\n",
    "    for j in range(len(t3_array[0])):\n",
    "            t3_corr[k+1+i][j]= abs(t3_array[k+i+2][j]-t2_array[i][3])\n",
    "            \n",
    "l = i+k+1\n",
    "for i in range(0,len(t2_array)):\n",
    "    for j in range(len(t3_array[0])):\n",
    "            t3_corr[l+1+i][j]= abs(t3_array[i+l+2][j]-t2_array[i][5])\n",
    "\n",
    "t3_corr1 = np.zeros((t3.shape[0]-1,t3.shape[1]))\n",
    "for i in range(len(t3_corr)):\n",
    "    for j in range(len(t3_corr[0])):\n",
    "        t3_corr1[i][j]= t3_corr[i][j]*t3_array[0][j]\n",
    "# print(t3_corr1)\n",
    "\n",
    "for i in range(len(t2_array)):\n",
    "    for j in range(len(t3_corr[0])):\n",
    "        corr_x1x2 +=  t3_corr1[i][j]\n",
    "k =i\n",
    "for i in range(0,len(t2_array)-1):\n",
    "    for j in range(len(t3_array[0])):\n",
    "        corr_x1x4 +=  t3_corr1[k+1+i][j]\n",
    "            \n",
    "l = i+k+1\n",
    "for i in range(0,len(t2_array)):\n",
    "    for j in range(len(t3_array[0])):\n",
    "        corr_x1x6 += t3_corr1[l+1+i][j] \n",
    "\n",
    "print(\"correlation between x1 and x2\")\n",
    "print(round(corr_x1x2, 4))\n",
    "print(\"correlation between x1 and x4\")\n",
    "print(round(corr_x1x4, 4))\n",
    "print(\"correlation between x1 and x6\")\n",
    "print(round(corr_x1x6, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation between x2 and x3\n",
      "0.2185\n",
      "correlation between x2 and x5\n",
      "0.0947\n"
     ]
    }
   ],
   "source": [
    "# Correlation of x2 with other features\n",
    "t4_corr = np.zeros((t4.shape[0]-1,t4.shape[1]))\n",
    "corr_x2x3 =0\n",
    "corr_x2x5 = 0\n",
    "\n",
    "for i in range(0,len(t2_array)-2):\n",
    "    for j in range(len(t4_array[0])):\n",
    "            t4_corr[i][j]= abs(t4_array[i+1][j]-t2_array[i][2])\n",
    "            \n",
    "k =i\n",
    "for i in range(0,len(t2_array)-1):\n",
    "    for j in range(len(t4_array[0])):\n",
    "            t4_corr[k+1+i][j]= abs(t4_array[k+i+2][j]-t2_array[i][4])\n",
    "            \n",
    "t4_corr1 = np.zeros((t4.shape[0]-1,t4.shape[1]))\n",
    "for i in range(len(t4_corr)):\n",
    "    for j in range(len(t4_corr[0])):\n",
    "        t4_corr1[i][j]= t4_corr[i][j]*t4_array[0][j]\n",
    "\n",
    "for i in range(len(t2_array)-2):\n",
    "    for j in range(len(t4_corr[0])):\n",
    "        corr_x2x3 +=  t4_corr1[i][j]\n",
    "k =i\n",
    "for i in range(0,len(t2_array)-1):\n",
    "    for j in range(len(t3_array[0])):\n",
    "        corr_x2x5 +=  t4_corr1[k+1+i][j]\n",
    "\n",
    "print(\"correlation between x2 and x3\")\n",
    "print(round(corr_x2x3,4))\n",
    "print(\"correlation between x2 and x5\")\n",
    "print(round(corr_x2x5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation between x3 and x2\n",
      "0.2346\n",
      "correlation between x3 and x5\n",
      "0.1128\n",
      "correlation between x3 and x6\n",
      "0.1192\n"
     ]
    }
   ],
   "source": [
    "# Correlation between x3 and other features\n",
    "t5_corr = np.zeros((t5.shape[0]-1,t5.shape[1]))\n",
    "cor_x3x2 = 0\n",
    "cor_x3x5 = 0\n",
    "cor_x3x6 = 0\n",
    "\n",
    "for i in range(0,len(t2_array)):\n",
    "    for j in range(len(t5_array[0])):\n",
    "            t5_corr[i][j]= abs(t5_array[i+1][j]-t2_array[i][1])\n",
    "            \n",
    "k =i\n",
    "for i in range(0,len(t2_array)-1):\n",
    "    for j in range(len(t5_array[0])):\n",
    "            t5_corr[k+1+i][j]= abs(t5_array[k+i+2][j]-t2_array[i][4])\n",
    "            \n",
    "l = i+k+1\n",
    "for i in range(0,len(t2_array)):\n",
    "    for j in range(len(t5_array[0])):\n",
    "            t5_corr[l+1+i][j]= abs(t5_array[i+l+2][j]-t2_array[i][5])\n",
    "            \n",
    "t5_corr1 = np.zeros((t5.shape[0]-1,t5.shape[1]))\n",
    "for i in range(len(t5_corr)):\n",
    "    for j in range(len(t5_corr[0])):\n",
    "        t5_corr1[i][j]= t5_corr[i][j]*t5_array[0][j]\n",
    "\n",
    "for i in range(len(t2_array)):\n",
    "    for j in range(len(t5_corr[0])):\n",
    "        cor_x3x2 +=  t5_corr1[i][j]\n",
    "k =i\n",
    "for i in range(0,len(t2_array)-1):\n",
    "    for j in range(len(t5_array[0])):\n",
    "        cor_x3x5 +=  t5_corr1[k+1+i][j]\n",
    "            \n",
    "l = i+k+1\n",
    "for i in range(0,len(t2_array)):\n",
    "    for j in range(len(t5_array[0])):\n",
    "        cor_x3x6 += t5_corr1[l+1+i][j] \n",
    "\n",
    "print(\"correlation between x3 and x2\")\n",
    "print(round(cor_x3x2, 4))\n",
    "print(\"correlation between x3 and x5\")\n",
    "print(round(cor_x3x5, 4))\n",
    "print(\"correlation between x3 and x6\")\n",
    "print(round(cor_x3x6, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation between x4 and x1\n",
      "0.1196\n",
      "correlation between x4 and x2\n",
      "0.1157\n",
      "correlation between x4 and x6\n",
      "0.1435\n"
     ]
    }
   ],
   "source": [
    "# Correlation between x4 and other features\n",
    "t6_corr = np.zeros((t6.shape[0]-1,t6.shape[1]))\n",
    "cor_x4x1 = 0\n",
    "cor_x4x2 = 0\n",
    "cor_x4x6 = 0\n",
    "\n",
    "for i in range(0,len(t2_array)-1):\n",
    "    for j in range(len(t6_array[0])):\n",
    "            t6_corr[i][j]= abs(t6_array[i+1][j]-t2_array[i][0])\n",
    "            \n",
    "k =i\n",
    "for i in range(0,len(t2_array)):\n",
    "    for j in range(len(t6_array[0])):\n",
    "            t6_corr[k+1+i][j]= abs(t6_array[k+i+2][j]-t2_array[i][1])\n",
    "            \n",
    "l = i+k+1\n",
    "for i in range(0,len(t2_array)):\n",
    "    for j in range(len(t6_array[0])):\n",
    "            t6_corr[l+1+i][j]= abs(t6_array[i+l+2][j]-t2_array[i][5])\n",
    "            \n",
    "t6_corr1 = np.zeros((t6.shape[0]-1,t6.shape[1]))\n",
    "for i in range(len(t6_corr)):\n",
    "    for j in range(len(t6_corr[0])):\n",
    "        t6_corr1[i][j]= t6_corr[i][j]*t6_array[0][j]\n",
    "\n",
    "for i in range(len(t2_array)-1):\n",
    "    for j in range(len(t6_corr[0])):\n",
    "        cor_x4x1 +=  t6_corr1[i][j]\n",
    "k =i\n",
    "for i in range(0,len(t2_array)):\n",
    "    for j in range(len(t6_array[0])):\n",
    "        cor_x4x2 +=  t6_corr1[k+1+i][j]\n",
    "            \n",
    "l = i+k+1\n",
    "for i in range(0,len(t2_array)):\n",
    "    for j in range(len(t6_array[0])):\n",
    "        cor_x4x6 += t6_corr1[l+1+i][j] \n",
    "\n",
    "print(\"correlation between x4 and x1\")\n",
    "print(round(cor_x4x1, 4))\n",
    "print(\"correlation between x4 and x2\")\n",
    "print(round(cor_x4x2, 4))\n",
    "print(\"correlation between x4 and x6\")\n",
    "print(round(cor_x4x6, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation between x5 and x2\n",
      "0.8528\n",
      "correlation between x5 and x3\n",
      "0.1178\n"
     ]
    }
   ],
   "source": [
    "# Correlation between x5 and other features\n",
    "t7_corr = np.zeros((t7.shape[0]-1,t7.shape[1]))\n",
    "cor_x5_x2 = 0\n",
    "cor_x5x3 = 0\n",
    "\n",
    "for i in range(0,len(t2_array)):\n",
    "    for j in range(len(t7_array[0])):\n",
    "            t7_corr[i][j]= abs(t7_array[i+1][j]-t2_array[i][1])\n",
    "            \n",
    "k =i\n",
    "for i in range(0,len(t2_array)-2):\n",
    "    for j in range(len(t7_array[0])):\n",
    "            t7_corr[k+1+i][j]= abs(t7_array[k+i+2][j]-t2_array[i][2])\n",
    "            \n",
    "t7_corr1 = np.zeros((t7.shape[0]-1,t7.shape[1]))\n",
    "for i in range(len(t7_corr)):\n",
    "    for j in range(len(t7_corr[0])):\n",
    "        t7_corr1[i][j]= t7_corr[i][j]*t7_array[0][j]\n",
    "        \n",
    "for i in range(len(t2_array)):\n",
    "    for j in range(len(t7_corr[0])):\n",
    "        cor_x5_x2 +=  t7_corr1[i][j]\n",
    "k =i\n",
    "for i in range(0,len(t2_array)-2):\n",
    "    for j in range(len(t7_array[0])):\n",
    "        cor_x5x3 +=  t7_corr1[k+1+i][j]\n",
    "            \n",
    "print(\"correlation between x5 and x2\")\n",
    "print(round(cor_x5_x2, 4))\n",
    "print(\"correlation between x5 and x3\")\n",
    "print(round(cor_x5x3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlation between x6 and x1\n",
      "0.1768\n",
      "correlation between x6 and x2\n",
      "0.1753\n",
      "correlation between x6 and x3\n",
      "0.139\n",
      "correlation between x6 and x4\n",
      "0.1431\n"
     ]
    }
   ],
   "source": [
    "# Correlation between x6 and other features\n",
    "t8_corr = np.zeros((t8.shape[0]-1,t8.shape[1]))\n",
    "cor_x6x1 = 0\n",
    "cor_x6x2 = 0\n",
    "cor_x6x3 = 0\n",
    "cor_x6x4 = 0\n",
    "\n",
    "for i in range(0,len(t2_array)-1):\n",
    "    for j in range(len(t8_array[0])):\n",
    "            t8_corr[i][j]= abs(t8_array[i+1][j]-t2_array[i][0])\n",
    "            \n",
    "k =i\n",
    "for i in range(0,len(t2_array)):\n",
    "    for j in range(len(t8_array[0])):\n",
    "            t8_corr[k+1+i][j]= abs(t8_array[k+i+2][j]-t2_array[i][1])\n",
    "            \n",
    "l = i+k+1\n",
    "for i in range(0,len(t2_array)-2):\n",
    "    for j in range(len(t8_array[0])):\n",
    "            t8_corr[l+1+i][j]= abs(t8_array[i+l+2][j]-t2_array[i][2])\n",
    "\n",
    "m = i+1+l\n",
    "for i in range(0,len(t2_array)-1):\n",
    "    for j in range(len(t8_array[0])):\n",
    "            t8_corr[m+1+i][j]= abs(t8_array[i+m+2][j]-t2_array[i][3])\n",
    "            \n",
    "t8_corr1 = np.zeros((t8.shape[0]-1,t8.shape[1]))\n",
    "for i in range(len(t8_corr)):\n",
    "    for j in range(len(t8_corr[0])):\n",
    "        t8_corr1[i][j]= t8_corr[i][j]*t8_array[0][j]\n",
    "\n",
    "for i in range(len(t2_array)-1):\n",
    "    for j in range(len(t8_corr[0])):\n",
    "        cor_x6x1 +=  t8_corr1[i][j]\n",
    "k =i\n",
    "for i in range(0,len(t2_array)):\n",
    "    for j in range(len(t8_array[0])):\n",
    "        cor_x6x2 +=  t8_corr1[k+1+i][j]\n",
    "            \n",
    "l = i+k+1\n",
    "for i in range(0,len(t2_array)-2):\n",
    "    for j in range(len(t8_array[0])):\n",
    "        cor_x6x3 += t8_corr1[l+1+i][j] \n",
    "\n",
    "m = i+1+l\n",
    "for i in range(0,len(t2_array)-1):\n",
    "    for j in range(len(t8_array[0])):\n",
    "        cor_x6x4+= t8_corr1[i+m+1][j]\n",
    "         \n",
    "print(\"correlation between x6 and x1\")\n",
    "print(round(cor_x6x1, 4))\n",
    "print(\"correlation between x6 and x2\")\n",
    "print(round(cor_x6x2, 4))\n",
    "print(\"correlation between x6 and x3\")\n",
    "print(round(cor_x6x3, 4))\n",
    "print(\"correlation between x6 and x4\")\n",
    "print(round(cor_x6x4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1598</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1194</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.2185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0947</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2346</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1128</td>\n",
       "      <td>0.1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>0.1196</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8528</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x6</th>\n",
       "      <td>0.1768</td>\n",
       "      <td>0.1753</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.1431</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x1      x2      x3      x4      x5      x6\n",
       "variable                                                \n",
       "x1        1.0000  0.1598  0.0000  0.1194  0.0000  0.1602\n",
       "x2        0.0000  1.0000  0.2185  0.0000  0.0947  0.0000\n",
       "x3        0.0000  0.2346  1.0000  0.0000  0.1128  0.1192\n",
       "x4        0.1196  0.1157  0.0000  1.0000  0.0000  0.1435\n",
       "x5        0.0000  0.8528  0.1178  0.0000  0.0000  0.0000\n",
       "x6        0.1768  0.1753  0.1390  0.1431  0.0000  0.0000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a correlation dataframe to a have reference of all the values\n",
    "correlations = pd.DataFrame([['x1', 1, 0.1598, 0, 0.1194, 0, 0.1602], \n",
    "                             ['x2', 0, 1, 0.2185, 0, 0.0947, 0],\n",
    "                             ['x3', 0, 0.2346, 1, 0, 0.1128, 0.1192],\n",
    "                             ['x4', 0.1196, 0.1157, 0, 1, 0, 0.1435],\n",
    "                             ['x5', 0, 0.8528, 0.1178, 0, 0, 0], \n",
    "                             ['x6', 0.1768, 0.1753, 0.139, 0.1431, 0, 0]],\n",
    "                             columns = ['variable', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6'])\n",
    "correlations.set_index('variable', inplace=True)\n",
    "correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Building a Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining CPDs\n",
    "cpd_x1x2 = TabularCPD(variable = 'x2', variable_card = 5,\n",
    "                       values = [t3_array[1,0:4],t3_array[2,0:4],t3_array[3,0:4],t3_array[4,0:4],t3_array[5,0:4]],\n",
    "                       evidence=['x1'], evidence_card=[4])\n",
    "\n",
    "cpd_x1x4 = TabularCPD('x4', 4,\n",
    "                      [t3_array[6,0:4],t3_array[7,0:4],t3_array[8,0:4],t3_array[9,0:4]],\n",
    "                      evidence=['x1'],evidence_card=[4])\n",
    "\n",
    "cpd_x1x6 = TabularCPD('x6', 5,\n",
    "                      [t3_array[10,0:4],t3_array[11,0:4],t3_array[12,0:4],t3_array[13,0:4],t3_array[14,0:4]],\n",
    "                      evidence=['x1'],evidence_card=[4])\n",
    "\n",
    "cpd_x1 = TabularCPD('x1', 4, [t2_array[0:4, 0]])\n",
    "\n",
    "cpd_x2x5 = TabularCPD('x5', 4,\n",
    "                      [t4_array[4,0:5],t4_array[5,0:5],t4_array[6,0:5],t4_array[7,0:5]],\n",
    "                      evidence=['x2'],evidence_card=[5])\n",
    "\n",
    "cpd_x2x3 = TabularCPD('x3', 3,\n",
    "                      [t4_array[1,0:5],t4_array[2,0:5],t4_array[3,0:5]],\n",
    "                      evidence=['x2'],evidence_card=[5])\n",
    "\n",
    "cpd_x3 = TabularCPD('x3', 3, [t5_array[0:3, 2]])\n",
    "\n",
    "cpd_x3x2 = TabularCPD('x2', 3,\n",
    "                     [t5_array[1,0:3], t5_array[2, 0:3], t5_array[3, 0:3]],\n",
    "                     evidence=['x3'], evidence_card=[3])\n",
    "\n",
    "cpd_x3x6 = TabularCPD('x6', 5, \n",
    "                     [t5_array[10, 0:3], t5_array[11, 0:3], t5_array[12, 0:3], t5_array[13, 0:3], t5_array[14, 0:3]],\n",
    "                     ['x3'], [3])\n",
    "\n",
    "cpd_x3x5 = TabularCPD('x5', 4, \n",
    "                     [t5_array[6, 0:3], t5_array[7, 0:3], t5_array[8, 0:3], t5_array[9, 0:3]],\n",
    "                     ['x3'], [3])\n",
    "\n",
    "cpd_x6x4 = TabularCPD('x4', 4,\n",
    "                      [t8_array[13, 0:5], t8_array[14, 0:5], t8_array[15, 0:5], t8_array[16, 0:5]],\n",
    "                      ['x6'], [5])\n",
    "\n",
    "cpd_x5x2 = TabularCPD('x2', 5, \n",
    "                      [t7_array[1, 0:4], t7_array[2, 0:4], t7_array[3, 0:4], t7_array[4, 0:4], t7_array[5, 0:4]],\n",
    "                      ['x5'], [4])\n",
    "\n",
    "cpd_x4x6 = TabularCPD('x6', 5, \n",
    "                     [t6_array[10, 0:4], t6_array[11, 0:4], t6_array[12, 0:4], t6_array[13, 0:4], t6_array[14, 0:4]],\n",
    "                     ['x4'], [4])\n",
    "\n",
    "cpd_x4x1 = TabularCPD('x1', 4,\n",
    "                     [t6_array[1, 0:4], t6_array[2, 0:4], t6_array[3, 0:4], t6_array[4, 0:4]],\n",
    "                     ['x4'], [4])\n",
    "\n",
    "cpd_x6x1 = TabularCPD('x1', 4,\n",
    "                     [t8_array[1, 0:5], t8_array[2, 0:5], t8_array[3, 0:5], t8_array[4, 0:5]],\n",
    "                     ['x6'], [5])\n",
    "\n",
    "cpd_x6 = TabularCPD('x6', 5, [t8_array[0:5, 0]])\n",
    "\n",
    "cpd_x2 = TabularCPD('x2', 5, [t4_array[0:5, 0]])\n",
    "\n",
    "cpd_x6x2 = TabularCPD('x2', 5,\n",
    "                      [t8_array[5, 0:5], t8_array[6, 0:5], t8_array[7, 0:5], t8_array[8, 0:5], t8_array[9, 0:5]],\n",
    "                      ['x6'], [5])\n",
    "\n",
    "# Normalizing the CPDs\n",
    "cpd_x1x2.normalize(True)\n",
    "cpd_x1x4.normalize(True)\n",
    "cpd_x1x6.normalize(True)\n",
    "cpd_x1.normalize(True)\n",
    "cpd_x2x5.normalize(True)\n",
    "cpd_x5x2.normalize(True)\n",
    "cpd_x2x3.normalize(True)\n",
    "cpd_x3.normalize(True)\n",
    "cpd_x3x2.normalize(True)\n",
    "cpd_x3x6.normalize(True)\n",
    "cpd_x6x4.normalize(True)\n",
    "cpd_x4x6.normalize(True)\n",
    "cpd_x4x1.normalize(True)\n",
    "cpd_x6x1.normalize(True)\n",
    "cpd_x6.normalize(True)\n",
    "cpd_x2.normalize(True)\n",
    "cpd_x6x2.normalize(True)\n",
    "cpd_x3x5.normalize(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating Models and generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Model\n",
    "model1 = BayesianModel()\n",
    "model1.add_nodes_from(['x1','x2','x3','x4','x5','x6'])\n",
    "model1.add_edges_from([('x1','x2'),('x1','x4'),('x1','x6'),('x2','x3'),('x2','x5')])\n",
    "model1.add_cpds(cpd_x1,cpd_x1x2,cpd_x1x4,cpd_x1x6,cpd_x2x3,cpd_x2x5)\n",
    "inference = BayesianModelSampling(model1)\n",
    "# print(inference.forward_sample(size=1000, return_type='dataframe'))\n",
    "data1 = inference.forward_sample(size=1000,return_type='dataframe')\n",
    "\n",
    "# Second Model\n",
    "model2 = BayesianModel()\n",
    "model2.add_nodes_from(['x1','x2','x3','x4','x5','x6'])\n",
    "model2.add_edges_from([('x1','x2'),('x1','x4'),('x6','x1'),('x2','x3'),('x2','x5')])\n",
    "model2.add_cpds(cpd_x6,cpd_x1x2,cpd_x1x4,cpd_x6x1,cpd_x2x3,cpd_x2x5)\n",
    "inference = BayesianModelSampling(model2)\n",
    "# print(inference.forward_sample(size=1000, return_type='dataframe'))\n",
    "data2 = inference.forward_sample(size=1000,return_type='dataframe')\n",
    "\n",
    "# Third Model\n",
    "model3 = BayesianModel()\n",
    "model3.add_nodes_from(['x1','x2','x3','x4','x5','x6'])\n",
    "model3.add_edges_from([('x2', 'x3'),('x2','x5'),('x3','x6'),('x6','x4'),('x4','x1')])\n",
    "model3.add_cpds(cpd_x2, cpd_x2x3, cpd_x2x5, cpd_x3x6, cpd_x6x4, cpd_x4x1)\n",
    "inference = BayesianModelSampling(model3)\n",
    "# print(inference.forward_sample(size=1000, return_type='dataframe'))\n",
    "data3 = inference.forward_sample(size=1000,return_type='dataframe')\n",
    "\n",
    "# Fourth Model\n",
    "model4 = BayesianModel()\n",
    "model4.add_nodes_from(['x1','x2','x3','x4','x5','x6'])\n",
    "model4.add_edges_from([('x3', 'x2'),('x2','x5'),('x3','x6'),('x6','x4'),('x4','x1')])\n",
    "model4.add_cpds(cpd_x3, cpd_x3x2, cpd_x2x5, cpd_x3x6, cpd_x6x4, cpd_x4x1)\n",
    "inference = BayesianModelSampling(model4)\n",
    "# print(inference.forward_sample(size=1000, return_type='dataframe'))\n",
    "data4 = inference.forward_sample(size=1000,return_type='dataframe')\n",
    "\n",
    "# Fifth Model\n",
    "model5 = BayesianModel()\n",
    "model5.add_nodes_from(['x1','x2','x3','x4','x5','x6'])\n",
    "model5.add_edges_from([('x1','x2'),('x1','x6'),('x6','x4'),('x2','x3'),('x3','x5')])\n",
    "model5.add_cpds(cpd_x1,cpd_x1x2,cpd_x1x6,cpd_x6x4,cpd_x2x3,cpd_x3x5)\n",
    "inference = BayesianModelSampling(model5)\n",
    "# print(inference.forward_sample(size=1000, return_type='dataframe'))\n",
    "data5 = inference.forward_sample(size=1000,return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "| x1_0 | 0.78  |\n",
      "+------+-------+\n",
      "| x1_1 | 0.015 |\n",
      "+------+-------+\n",
      "| x1_2 | 0.055 |\n",
      "+------+-------+\n",
      "| x1_3 | 0.15  |\n",
      "+------+-------+\n",
      "+------+----------------------+--------------------+---------------------+---------------------+\n",
      "| x1   | x1_0                 | x1_1               | x1_2                | x1_3                |\n",
      "+------+----------------------+--------------------+---------------------+---------------------+\n",
      "| x2_0 | 0.231                | 0.6666666666666666 | 0.4545454545454546  | 0.4                 |\n",
      "+------+----------------------+--------------------+---------------------+---------------------+\n",
      "| x2_1 | 0.365                | 0.0                | 0.09090909090909091 | 0.2                 |\n",
      "+------+----------------------+--------------------+---------------------+---------------------+\n",
      "| x2_2 | 0.026000000000000002 | 0.0                | 0.0                 | 0.033               |\n",
      "+------+----------------------+--------------------+---------------------+---------------------+\n",
      "| x2_3 | 0.17300000000000001  | 0.0                | 0.18181818181818182 | 0.16699999999999998 |\n",
      "+------+----------------------+--------------------+---------------------+---------------------+\n",
      "| x2_4 | 0.205                | 0.3333333333333333 | 0.27272727272727276 | 0.2                 |\n",
      "+------+----------------------+--------------------+---------------------+---------------------+\n",
      "+------+----------------------+------+-------+---------------------+\n",
      "| x1   | x1_0                 | x1_1 | x1_2  | x1_3                |\n",
      "+------+----------------------+------+-------+---------------------+\n",
      "| x4_0 | 0.737                | 1.0  | 0.727 | 0.567               |\n",
      "+------+----------------------+------+-------+---------------------+\n",
      "| x4_1 | 0.077                | 0.0  | 0.273 | 0.19999999999999996 |\n",
      "+------+----------------------+------+-------+---------------------+\n",
      "| x4_2 | 0.013000000000000001 | 0.0  | 0.0   | 0.0                 |\n",
      "+------+----------------------+------+-------+---------------------+\n",
      "| x4_3 | 0.17300000000000001  | 0.0  | 0.0   | 0.23299999999999996 |\n",
      "+------+----------------------+------+-------+---------------------+\n",
      "+------+----------------------+--------------------+-------+------+\n",
      "| x1   | x1_0                 | x1_1               | x1_2  | x1_3 |\n",
      "+------+----------------------+--------------------+-------+------+\n",
      "| x6_0 | 0.019019019019019017 | 0.0                | 0.0   | 0.0  |\n",
      "+------+----------------------+--------------------+-------+------+\n",
      "| x6_1 | 0.28228228228228225  | 0.6666666666666666 | 0.545 | 0.4  |\n",
      "+------+----------------------+--------------------+-------+------+\n",
      "| x6_2 | 0.12812812812812813  | 0.3333333333333333 | 0.091 | 0.2  |\n",
      "+------+----------------------+--------------------+-------+------+\n",
      "| x6_3 | 0.3523523523523524   | 0.0                | 0.182 | 0.2  |\n",
      "+------+----------------------+--------------------+-------+------+\n",
      "| x6_4 | 0.2182182182182182   | 0.0                | 0.182 | 0.2  |\n",
      "+------+----------------------+--------------------+-------+------+\n",
      "+------+---------------------+---------------------+------+---------------------+---------------------+\n",
      "| x2   | x2_0                | x2_1                | x2_2 | x2_3                | x2_4                |\n",
      "+------+---------------------+---------------------+------+---------------------+---------------------+\n",
      "| x3_0 | 0.12712712712712712 | 0.26600000000000007 | 0.2  | 0.17600000000000002 | 0.11900000000000001 |\n",
      "+------+---------------------+---------------------+------+---------------------+---------------------+\n",
      "| x3_1 | 0.7457457457457457  | 0.656               | 0.8  | 0.706               | 0.5                 |\n",
      "+------+---------------------+---------------------+------+---------------------+---------------------+\n",
      "| x3_2 | 0.12712712712712712 | 0.07800000000000001 | 0.0  | 0.11800000000000001 | 0.381               |\n",
      "+------+---------------------+---------------------+------+---------------------+---------------------+\n",
      "+------+-------+---------------------+------+---------------------+---------------------+\n",
      "| x2   | x2_0  | x2_1                | x2_2 | x2_3                | x2_4                |\n",
      "+------+-------+---------------------+------+---------------------+---------------------+\n",
      "| x5_0 | 0.418 | 0.3373737373737373  | 0.6  | 0.382               | 0.33399999999999996 |\n",
      "+------+-------+---------------------+------+---------------------+---------------------+\n",
      "| x5_1 | 0.073 | 0.1101010101010101  | 0.4  | 0.147               | 0.095               |\n",
      "+------+-------+---------------------+------+---------------------+---------------------+\n",
      "| x5_2 | 0.109 | 0.12626262626262627 | 0.0  | 0.11800000000000001 | 0.071               |\n",
      "+------+-------+---------------------+------+---------------------+---------------------+\n",
      "| x5_3 | 0.4   | 0.4262626262626263  | 0.0  | 0.353               | 0.5                 |\n",
      "+------+-------+---------------------+------+---------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "cpds = model1.get_cpds()\n",
    "for cpd in cpds:\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating the models using K2 score on the generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 K2 Score on data 1: -6415.14369220124\n",
      "Model 1 K2 Score on data 2: -6423.653941212753\n",
      "Model 1 K2 Score on data 3: -6489.2680366884215\n",
      "Model 1 K2 Score on data 4: -6488.807323528655\n",
      "Model 1 K2 Score on data 5: -6451.506222249914\n",
      "\n",
      "K2 score on data\n",
      "Model 1 K2 Score on data: -32012.15654841258\n",
      "Model 2 K2 Score on data: -32018.582623350118\n",
      "Model 3 K2 Score on data: -32078.419983949345\n",
      "Model 4 K2 Score on data: -32076.58515189401\n",
      "Model 5 K2 Score on data: -32421.27148585546\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the models on the data sets generated by them\n",
    "data = pd.concat([data1, data2, data3, data4, data5])\n",
    "data.shape\n",
    "\n",
    "k2 = K2Score(data)\n",
    "k21 = K2Score(data1) #data1 is data obtained by sampling from model 1\n",
    "k22 = K2Score(data2)\n",
    "k23 = K2Score(data3)\n",
    "k24 = K2Score(data4)\n",
    "k25 = K2Score(data5)\n",
    "\n",
    "# K2 score of each model on the data generated by its own (1000x6)\n",
    "print('Model 1 K2 Score on data 1: ' + str(k21.score(model1)))\n",
    "print('Model 1 K2 Score on data 2: ' + str(k21.score(model2)))\n",
    "print('Model 1 K2 Score on data 3: ' + str(k21.score(model3)))\n",
    "print('Model 1 K2 Score on data 4: ' + str(k21.score(model4)))\n",
    "print('Model 1 K2 Score on data 5: ' + str(k21.score(model5)))\n",
    "\n",
    "# K2 score of each model on the entire data (5000x6)\n",
    "print('\\nK2 score on data')\n",
    "print('Model 1 K2 Score on data: ' + str(k2.score(model1))) # model 1 is the best model\n",
    "print('Model 2 K2 Score on data: ' + str(k2.score(model2)))\n",
    "print('Model 3 K2 Score on data: ' + str(k2.score(model3)))\n",
    "print('Model 4 K2 Score on data: ' + str(k2.score(model4)))\n",
    "print('Model 5 K2 Score on data: ' + str(k2.score(model5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find the high and low probability patterns of 'th'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The high probability has a pattern of 011031 and occurs 21 times. Please see below.\n",
      "     x1  x2  x3  x4  x5  x6  count\n",
      "106   0   1   1   0   3   1     21\n",
      "108   0   1   1   0   3   3     19\n",
      "16    0   0   1   0   0   3     18\n",
      "\n",
      "The low probability has a pattern of 000001 and occurs 1 time. Please see below.\n",
      "     x1  x2  x3  x4  x5  x6  count\n",
      "0     0   0   0   0   0   1      1\n",
      "302   2   0   1   0   2   3      1\n",
      "300   2   0   1   0   1   1      1\n"
     ]
    }
   ],
   "source": [
    "# Finding 'th' highest frequency pattern\n",
    "frequency = data1.groupby(['x1', 'x2', 'x3', 'x4', 'x5', 'x6']).size().to_frame('count').reset_index()\n",
    "print('The high probability has a pattern of 011031 and occurs 21 times. Please see below.')\n",
    "print(frequency.sort_values('count', ascending = False).iloc[0:3, ])\n",
    "\n",
    "\n",
    "# Find 'th' lowest frequency pattern\n",
    "print('\\nThe low probability has a pattern of 000001 and occurs 1 time. Please see below.')\n",
    "print(frequency.sort_values('count', ascending = True).iloc[0:3, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additonal:- Finding the best Bayesian Model for the obtained 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('x1', 'x6'), ('x1', 'x2'), ('x2', 'x3'), ('x2', 'x5'), ('x4', 'x1'), ('x4', 'x6')]\n"
     ]
    }
   ],
   "source": [
    "# Finding the best Bayesian model which describes the data using hillclimbsearch\n",
    "hc = HillClimbSearch(data, scoring_method=K2Score(data))\n",
    "best_model = hc.estimate()\n",
    "\n",
    "print(best_model.edges())\n",
    "# the best edges obtained by the search are different from any of the model edges we defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model check:  True \n",
      "\n",
      "Model K2 Score:  -32011.615730167887 \n",
      "\n",
      "The cpds obtained using Bayesian Parameter estimation are: \n",
      "\n",
      "+-------+----------------------+----------------------+----------------------+----------------------+\n",
      "| x4    | x4(0)                | x4(1)                | x4(2)                | x4(3)                |\n",
      "+-------+----------------------+----------------------+----------------------+----------------------+\n",
      "| x1(0) | 0.7805289814293753   | 0.5623931623931624   | 0.8913043478260869   | 0.7737665463297232   |\n",
      "+-------+----------------------+----------------------+----------------------+----------------------+\n",
      "| x1(1) | 0.021947101857062466 | 0.006837606837606838 | 0.021739130434782608 | 0.007220216606498195 |\n",
      "+-------+----------------------+----------------------+----------------------+----------------------+\n",
      "| x1(2) | 0.06921778277996624  | 0.1623931623931624   | 0.021739130434782608 | 0.010830324909747292 |\n",
      "+-------+----------------------+----------------------+----------------------+----------------------+\n",
      "| x1(3) | 0.12830613393359594  | 0.26837606837606837  | 0.06521739130434782  | 0.20818291215403129  |\n",
      "+-------+----------------------+----------------------+----------------------+----------------------+\n",
      "+-------+----------------------+----------------------+----------------------+----------------------+\n",
      "| x1    | x1(0)                | x1(1)                | x1(2)                | x1(3)                |\n",
      "+-------+----------------------+----------------------+----------------------+----------------------+\n",
      "| x6(0) | 0.016631467793030624 | 0.022222222222222223 | 0.002840909090909091 | 0.006329113924050633 |\n",
      "+-------+----------------------+----------------------+----------------------+----------------------+\n",
      "| x6(1) | 0.43479408658922913  | 0.6555555555555556   | 0.7045454545454546   | 0.489873417721519    |\n",
      "+-------+----------------------+----------------------+----------------------+----------------------+\n",
      "| x6(2) | 0.10929250263991552  | 0.17777777777777778  | 0.07670454545454546  | 0.14303797468354432  |\n",
      "+-------+----------------------+----------------------+----------------------+----------------------+\n",
      "| x6(3) | 0.25422386483632525  | 0.06666666666666667  | 0.11079545454545454  | 0.20126582278481012  |\n",
      "+-------+----------------------+----------------------+----------------------+----------------------+\n",
      "| x6(4) | 0.18505807814149947  | 0.07777777777777778  | 0.10511363636363637  | 0.15949367088607594  |\n",
      "+-------+----------------------+----------------------+----------------------+----------------------+\n",
      "+-------+---------------------+----------------------+---------------------+---------------------+\n",
      "| x1    | x1(0)               | x1(1)                | x1(2)               | x1(3)               |\n",
      "+-------+---------------------+----------------------+---------------------+---------------------+\n",
      "| x2(0) | 0.2539598732840549  | 0.5333333333333333   | 0.45170454545454547 | 0.31645569620253167 |\n",
      "+-------+---------------------+----------------------+---------------------+---------------------+\n",
      "| x2(1) | 0.34978880675818375 | 0.07777777777777778  | 0.13636363636363635 | 0.25569620253164554 |\n",
      "+-------+---------------------+----------------------+---------------------+---------------------+\n",
      "| x2(2) | 0.1100844772967265  | 0.08888888888888889  | 0.07102272727272728 | 0.12658227848101267 |\n",
      "+-------+---------------------+----------------------+---------------------+---------------------+\n",
      "| x2(3) | 0.11325237592397043 | 0.022222222222222223 | 0.1278409090909091  | 0.1189873417721519  |\n",
      "+-------+---------------------+----------------------+---------------------+---------------------+\n",
      "| x2(4) | 0.17291446673706443 | 0.2777777777777778   | 0.21306818181818182 | 0.18227848101265823 |\n",
      "+-------+---------------------+----------------------+---------------------+---------------------+\n",
      "+-------+---------------------+---------------------+-----------------------+---------------------+--------------------+\n",
      "| x2    | x2(0)               | x2(1)               | x2(2)                 | x2(3)               | x2(4)              |\n",
      "+-------+---------------------+---------------------+-----------------------+---------------------+--------------------+\n",
      "| x3(0) | 0.15162200282087446 | 0.3099304237824162  | 0.20218579234972678   | 0.17926186291739896 | 0.111358574610245  |\n",
      "+-------+---------------------+---------------------+-----------------------+---------------------+--------------------+\n",
      "| x3(1) | 0.656558533145275   | 0.5610373181530677  | 0.7959927140255009    | 0.7363796133567663  | 0.5133630289532294 |\n",
      "+-------+---------------------+---------------------+-----------------------+---------------------+--------------------+\n",
      "| x3(2) | 0.1918194640338505  | 0.12903225806451613 | 0.0018214936247723133 | 0.0843585237258348  | 0.3752783964365256 |\n",
      "+-------+---------------------+---------------------+-----------------------+---------------------+--------------------+\n",
      "+-------+---------------------+---------------------+-----------------------+---------------------+---------------------+\n",
      "| x2    | x2(0)               | x2(1)               | x2(2)                 | x2(3)               | x2(4)               |\n",
      "+-------+---------------------+---------------------+-----------------------+---------------------+---------------------+\n",
      "| x5(0) | 0.4214235377026075  | 0.3356510745891277  | 0.6018181818181818    | 0.33157894736842103 | 0.3548387096774194  |\n",
      "+-------+---------------------+---------------------+-----------------------+---------------------+---------------------+\n",
      "| x5(1) | 0.08738548273431994 | 0.10998735777496839 | 0.38                  | 0.15087719298245614 | 0.0867630700778643  |\n",
      "+-------+---------------------+---------------------+-----------------------+---------------------+---------------------+\n",
      "| x5(2) | 0.10570824524312897 | 0.12895069532237674 | 0.0018181818181818182 | 0.11754385964912281 | 0.08453837597330367 |\n",
      "+-------+---------------------+---------------------+-----------------------+---------------------+---------------------+\n",
      "| x5(3) | 0.3854827343199436  | 0.4254108723135272  | 0.016363636363636365  | 0.4                 | 0.4738598442714127  |\n",
      "+-------+---------------------+---------------------+-----------------------+---------------------+---------------------+\n",
      "+-------+------------+\n",
      "| x4(0) | 0.709632   |\n",
      "+-------+------------+\n",
      "| x4(1) | 0.116307   |\n",
      "+-------+------------+\n",
      "| x4(2) | 0.00859313 |\n",
      "+-------+------------+\n",
      "| x4(3) | 0.165468   |\n",
      "+-------+------------+\n"
     ]
    }
   ],
   "source": [
    "# Bayesian Model and parameter estimation\n",
    "model = BayesianModel([('x1', 'x6'), ('x1', 'x2'), ('x2', 'x3'), ('x2', 'x5'), ('x4', 'x1')])\n",
    "\n",
    "# Bayesian Parameter Estimation\n",
    "model.fit(data, estimator=BayesianEstimator, prior_type='K2', equivalent_sample_size=50)\n",
    "\n",
    "# check_model checks for the network structure and CPDs and verifies that the CPDs are correctly \n",
    "# defined and sum to 1.\n",
    "print('Model check: ', model.check_model(), '\\n')\n",
    "\n",
    "# Evaluating the fit\n",
    "k2 = K2Score(data)\n",
    "\n",
    "print('Model K2 Score: ', str(k2.score(model)), '\\n') #the K2 score is least by a small margin when compared the above models\n",
    "\n",
    "print('The cpds obtained using Bayesian Parameter estimation are: \\n')\n",
    "cpds = model.get_cpds()\n",
    "for cpd in cpds:\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferences using Bayesian Network: \n",
      "Probability of x2:\n",
      "+------+-----------+\n",
      "| x2   |   phi(x2) |\n",
      "+======+===========+\n",
      "| x2_0 |    0.2826 |\n",
      "+------+-----------+\n",
      "| x2_1 |    0.3152 |\n",
      "+------+-----------+\n",
      "| x2_2 |    0.1096 |\n",
      "+------+-----------+\n",
      "| x2_3 |    0.1136 |\n",
      "+------+-----------+\n",
      "| x2_4 |    0.1791 |\n",
      "+------+-----------+\n",
      "\n",
      "Coditional Probabilty of x5 given x2=1, x3=1, x1=0, x4=0, x6=1:\n",
      "+------+-----------+\n",
      "| x5   |   phi(x5) |\n",
      "+======+===========+\n",
      "| x5_0 |    0.3357 |\n",
      "+------+-----------+\n",
      "| x5_1 |    0.1100 |\n",
      "+------+-----------+\n",
      "| x5_2 |    0.1290 |\n",
      "+------+-----------+\n",
      "| x5_3 |    0.4254 |\n",
      "+------+-----------+\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.inference import VariableElimination\n",
    "infer = VariableElimination(model)\n",
    "\n",
    "print('Inferences using Bayesian Network: ')\n",
    "print('Probability of x2:')\n",
    "print(infer.query(['x2'])['x2'])\n",
    "\n",
    "print('\\nCoditional Probabilty of x5 given x2=1, x3=1, x1=0, x4=0, x6=1:')\n",
    "print(infer.query(['x5'], evidence={'x2': 1, 'x3': 1, 'x1':0, 'x4':0, 'x6':1}) ['x5']) #this is the pattern for highest\n",
    "#'th' probability. As expected the probabilty of x5 taking the value of 3 is highest because it occurs 83 times when the other\n",
    "# variable values are fixed and the next highest being x5=0 occuring 81 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time for inference using \"Bayesian Network\":  0.06345370001508854\n"
     ]
    }
   ],
   "source": [
    "# Computational time of inference using Bayesian Network\n",
    "import time\n",
    "time_start = time.clock()\n",
    "infer = VariableElimination(model)\n",
    "infer.query(['x3'])['x3']\n",
    "infer.query(['x2'], evidence={'x1':0, 'x6':1}) ['x2']\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print('Computation time for inference using \"Bayesian Network\": ', time_elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - Converting to a Markov Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferences using Markov network: \n",
      "Probability of x2:\n",
      "+------+-----------+\n",
      "| x2   |   phi(x2) |\n",
      "+======+===========+\n",
      "| x2_0 |    0.2826 |\n",
      "+------+-----------+\n",
      "| x2_1 |    0.3152 |\n",
      "+------+-----------+\n",
      "| x2_2 |    0.1096 |\n",
      "+------+-----------+\n",
      "| x2_3 |    0.1136 |\n",
      "+------+-----------+\n",
      "| x2_4 |    0.1791 |\n",
      "+------+-----------+\n",
      "\n",
      "Coditional Probabilty of x5 given x2=1, x3=1, x1=0, x4=0, x6=1:\n",
      "+------+-----------+\n",
      "| x5   |   phi(x5) |\n",
      "+======+===========+\n",
      "| x5_0 |    0.3357 |\n",
      "+------+-----------+\n",
      "| x5_1 |    0.1100 |\n",
      "+------+-----------+\n",
      "| x5_2 |    0.1290 |\n",
      "+------+-----------+\n",
      "| x5_3 |    0.4254 |\n",
      "+------+-----------+\n"
     ]
    }
   ],
   "source": [
    "mm = model.to_markov_model()\n",
    "mm.nodes()\n",
    "mm.edges()\n",
    "\n",
    "# Finding inferences using Markov Network\n",
    "infer = VariableElimination(mm)\n",
    "\n",
    "print('Inferences using Markov network: ')\n",
    "print('Probability of x2:')\n",
    "print(infer.query(['x2'])['x2'])\n",
    "\n",
    "print('\\nCoditional Probabilty of x5 given x2=1, x3=1, x1=0, x4=0, x6=1:')\n",
    "print(infer.query(['x5'], evidence={'x2': 1, 'x3': 1, 'x1':0, 'x4':0, 'x6':1}) ['x5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time for inference using \"Markov Network\":  0.05844380002235994\n"
     ]
    }
   ],
   "source": [
    "# Computational time of inference using Markov Network\n",
    "import time\n",
    "time_start = time.clock()\n",
    "infer = VariableElimination(mm)\n",
    "infer.query(['x3'])['x3']\n",
    "infer.query(['x2'], evidence={'x1':0, 'x6':1}) ['x2']\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print('Computation time for inference using \"Markov Network\": ', time_elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 - AND dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import HillClimbSearch\n",
    "from pgmpy.estimators import ExhaustiveSearch\n",
    "from pgmpy.estimators import K2Score\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import BayesianEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('f3', 'f4'), ('f3', 'f9'), ('f3', 'f8'), ('f5', 'f9'), ('f5', 'f3'), ('f9', 'f8'), ('f9', 'f7'), ('f9', 'f1'), ('f9', 'f6'), ('f9', 'f2'), ('f9', 'f4')]\n"
     ]
    }
   ],
   "source": [
    "# Loading AND_Features dataset and finding the best structure for the model\n",
    "df = pd.read_csv('AND-Features.csv')\n",
    "df = df.iloc[:, 2:11]\n",
    "\n",
    "hc = HillClimbSearch(df, scoring_method=K2Score(df))\n",
    "best_model = hc.estimate()\n",
    "\n",
    "print(best_model.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 check:  True\n",
      "Model 2 check:  True\n",
      "Model 3 check:  True\n"
     ]
    }
   ],
   "source": [
    "# Bayesian Model and parameter estimation\n",
    "model1 = BayesianModel([('f3', 'f4'), ('f3', 'f9'), ('f3', 'f8'), ('f5', 'f9'), ('f5', 'f3'), \n",
    "                       ('f9', 'f8'), ('f9', 'f7'), ('f9', 'f1'), ('f9', 'f6'), ('f9', 'f2'), ('f9', 'f4')])\n",
    "\n",
    "# Bayesian Parameter Estimation\n",
    "est = BayesianEstimator(model1, df)\n",
    "\n",
    "cpd_f1 = est.estimate_cpd('f1', prior_type='K2', equivalent_sample_size=50)\n",
    "cpd_f2 = est.estimate_cpd('f2', prior_type='K2', equivalent_sample_size=50)\n",
    "cpd_f3 = est.estimate_cpd('f3', prior_type='K2', equivalent_sample_size=50)\n",
    "cpd_f4 = est.estimate_cpd('f4', prior_type='K2', equivalent_sample_size=50)\n",
    "cpd_f5 = est.estimate_cpd('f5', prior_type='K2', equivalent_sample_size=50)\n",
    "cpd_f6 = est.estimate_cpd('f6', prior_type='K2', equivalent_sample_size=50)\n",
    "cpd_f7 = est.estimate_cpd('f7', prior_type='K2', equivalent_sample_size=50)\n",
    "cpd_f8 = est.estimate_cpd('f8', prior_type='K2', equivalent_sample_size=50)\n",
    "cpd_f9 = est.estimate_cpd('f9', prior_type='K2', equivalent_sample_size=50)\n",
    "\n",
    "# Associating the CPDs with the network\n",
    "model1.add_cpds(cpd_f1, cpd_f2, cpd_f3, cpd_f4, cpd_f5, cpd_f6, cpd_f7, cpd_f8, cpd_f9)\n",
    "\n",
    "# check_model checks for the network structure and CPDs and verifies that the CPDs are correctly \n",
    "# defined and sum to 1.\n",
    "print('Model 1 check: ', model1.check_model())\n",
    "\n",
    "#######################\n",
    "##### Model 2 #####\n",
    "#######################\n",
    "model2 = BayesianModel([('f3', 'f4'), ('f3', 'f9'), ('f3', 'f8'), ('f5', 'f3'), \n",
    "                       ('f9', 'f7'), ('f9', 'f1'), ('f9', 'f6'), ('f9', 'f2'), ('f9', 'f4')])\n",
    "\n",
    "# Bayesian Parameter Estimation using fit()\n",
    "model2.fit(df, estimator=BayesianEstimator, prior_type='K2', equivalent_sample_size=50)\n",
    "\n",
    "# check_model checks for the network structure and CPDs and verifies that the CPDs are correctly \n",
    "# defined and sum to 1.\n",
    "print('Model 2 check: ', model2.check_model())\n",
    "\n",
    "#######################\n",
    "##### Model 3 #####\n",
    "#######################\n",
    "model3 = BayesianModel([('f3', 'f4'), ('f3', 'f9'), ('f3', 'f8'), ('f5', 'f9'), ('f3', 'f5'), \n",
    "                       ('f9', 'f8'), ('f9', 'f7'), ('f9', 'f1'), ('f9', 'f6'), ('f9', 'f2'), ('f9', 'f4')])\n",
    "\n",
    "# Bayesian Parameter Estimation\n",
    "model3.fit(df, estimator=BayesianEstimator, prior_type='K2', equivalent_sample_size=50)\n",
    "\n",
    "# check_model checks for the network structure and CPDs and verifies that the CPDs are correctly \n",
    "# defined and sum to 1.\n",
    "print('Model 3 check: ', model3.check_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 K2 Score: -9462.704892371386\n",
      "Model 2 K2 Score: -9597.068195873735\n",
      "Model 3 K2 Score: -9463.727521719544\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the fit\n",
    "k2 = K2Score(df)\n",
    "\n",
    "print('Model 1 K2 Score: ' + str(k2.score(model1)))\n",
    "print('Model 2 K2 Score: ' + str(k2.score(model2)))\n",
    "print('Model 3 K2 Score: ' + str(k2.score(model3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cpds obtained using Bayesian Parameter estimation are: \n",
      "\n",
      "+-------+---------------------+---------------------+\n",
      "| f9    | f9(1)               | f9(2)               |\n",
      "+-------+---------------------+---------------------+\n",
      "| f1(0) | 0.19913419913419914 | 0.10709838107098381 |\n",
      "+-------+---------------------+---------------------+\n",
      "| f1(1) | 0.4458874458874459  | 0.2602739726027397  |\n",
      "+-------+---------------------+---------------------+\n",
      "| f1(2) | 0.26406926406926406 | 0.3686176836861768  |\n",
      "+-------+---------------------+---------------------+\n",
      "| f1(3) | 0.09090909090909091 | 0.2640099626400996  |\n",
      "+-------+---------------------+---------------------+\n",
      "+-------+----------------------+----------------------+\n",
      "| f9    | f9(1)                | f9(2)                |\n",
      "+-------+----------------------+----------------------+\n",
      "| f2(0) | 0.14655172413793102  | 0.1865671641791045   |\n",
      "+-------+----------------------+----------------------+\n",
      "| f2(1) | 0.6163793103448276   | 0.48383084577114427  |\n",
      "+-------+----------------------+----------------------+\n",
      "| f2(2) | 0.14655172413793102  | 0.12686567164179105  |\n",
      "+-------+----------------------+----------------------+\n",
      "| f2(3) | 0.017241379310344827 | 0.012437810945273632 |\n",
      "+-------+----------------------+----------------------+\n",
      "| f2(4) | 0.07327586206896551  | 0.19029850746268656  |\n",
      "+-------+----------------------+----------------------+\n",
      "+-------+---------------------+----------------------+----------------------+-------+\n",
      "| f5    | f5(0)               | f5(1)                | f5(2)                | f5(3) |\n",
      "+-------+---------------------+----------------------+----------------------+-------+\n",
      "| f3(0) | 0.20967741935483872 | 0.024390243902439025 | 0.11823899371069183  | 0.125 |\n",
      "+-------+---------------------+----------------------+----------------------+-------+\n",
      "| f3(1) | 0.7419354838709677  | 0.9512195121951219   | 0.8528301886792453   | 0.375 |\n",
      "+-------+---------------------+----------------------+----------------------+-------+\n",
      "| f3(2) | 0.04838709677419355 | 0.024390243902439025 | 0.028930817610062894 | 0.5   |\n",
      "+-------+---------------------+----------------------+----------------------+-------+\n",
      "+-------+---------------------+----------------------+-------+----------------------+---------------------+---------------------+\n",
      "| f3    | f3(0)               | f3(0)                | f3(1) | f3(1)                | f3(2)               | f3(2)               |\n",
      "+-------+---------------------+----------------------+-------+----------------------+---------------------+---------------------+\n",
      "| f9    | f9(1)               | f9(2)                | f9(1) | f9(2)                | f9(1)               | f9(2)               |\n",
      "+-------+---------------------+----------------------+-------+----------------------+---------------------+---------------------+\n",
      "| f4(0) | 0.12903225806451613 | 0.18018018018018017  | 0.36  | 0.391304347826087    | 0.18181818181818182 | 0.05555555555555555 |\n",
      "+-------+---------------------+----------------------+-------+----------------------+---------------------+---------------------+\n",
      "| f4(1) | 0.5161290322580645  | 0.15315315315315314  | 0.285 | 0.1889055472263868   | 0.2727272727272727  | 0.16666666666666666 |\n",
      "+-------+---------------------+----------------------+-------+----------------------+---------------------+---------------------+\n",
      "| f4(2) | 0.22580645161290322 | 0.4954954954954955   | 0.08  | 0.049475262368815595 | 0.09090909090909091 | 0.05555555555555555 |\n",
      "+-------+---------------------+----------------------+-------+----------------------+---------------------+---------------------+\n",
      "| f4(3) | 0.0967741935483871  | 0.13513513513513514  | 0.265 | 0.3583208395802099   | 0.09090909090909091 | 0.3055555555555556  |\n",
      "+-------+---------------------+----------------------+-------+----------------------+---------------------+---------------------+\n",
      "| f4(4) | 0.03225806451612903 | 0.036036036036036036 | 0.01  | 0.01199400299850075  | 0.36363636363636365 | 0.4166666666666667  |\n",
      "+-------+---------------------+----------------------+-------+----------------------+---------------------+---------------------+\n",
      "+-------+-----------+\n",
      "| f5(0) | 0.178641  |\n",
      "+-------+-----------+\n",
      "| f5(1) | 0.0378641 |\n",
      "+-------+-----------+\n",
      "| f5(2) | 0.769903  |\n",
      "+-------+-----------+\n",
      "| f5(3) | 0.0135922 |\n",
      "+-------+-----------+\n",
      "+-------+----------------------+---------------------+\n",
      "| f9    | f9(1)                | f9(2)               |\n",
      "+-------+----------------------+---------------------+\n",
      "| f6(0) | 0.008658008658008658 | 0.0186799501867995  |\n",
      "+-------+----------------------+---------------------+\n",
      "| f6(1) | 0.31601731601731603  | 0.16936488169364883 |\n",
      "+-------+----------------------+---------------------+\n",
      "| f6(2) | 0.5887445887445888   | 0.6027397260273972  |\n",
      "+-------+----------------------+---------------------+\n",
      "| f6(3) | 0.08658008658008658  | 0.20921544209215442 |\n",
      "+-------+----------------------+---------------------+\n",
      "+-------+---------------------+---------------------+\n",
      "| f9    | f9(1)               | f9(2)               |\n",
      "+-------+---------------------+---------------------+\n",
      "| f7(0) | 0.2510822510822511  | 0.526774595267746   |\n",
      "+-------+---------------------+---------------------+\n",
      "| f7(1) | 0.46320346320346323 | 0.30759651307596514 |\n",
      "+-------+---------------------+---------------------+\n",
      "| f7(2) | 0.23376623376623376 | 0.0448318804483188  |\n",
      "+-------+---------------------+---------------------+\n",
      "| f7(3) | 0.05194805194805195 | 0.12079701120797011 |\n",
      "+-------+---------------------+---------------------+\n",
      "+-------+---------------------+---------------------+-------+---------------------+---------------------+----------------------+\n",
      "| f3    | f3(0)               | f3(0)               | f3(1) | f3(1)               | f3(2)               | f3(2)                |\n",
      "+-------+---------------------+---------------------+-------+---------------------+---------------------+----------------------+\n",
      "| f9    | f9(1)               | f9(2)               | f9(1) | f9(2)               | f9(1)               | f9(2)                |\n",
      "+-------+---------------------+---------------------+-------+---------------------+---------------------+----------------------+\n",
      "| f8(0) | 0.1935483870967742  | 0.16216216216216217 | 0.17  | 0.18140929535232383 | 0.09090909090909091 | 0.027777777777777776 |\n",
      "+-------+---------------------+---------------------+-------+---------------------+---------------------+----------------------+\n",
      "| f8(1) | 0.2903225806451613  | 0.11711711711711711 | 0.375 | 0.20839580209895053 | 0.45454545454545453 | 0.1111111111111111   |\n",
      "+-------+---------------------+---------------------+-------+---------------------+---------------------+----------------------+\n",
      "| f8(2) | 0.3870967741935484  | 0.2072072072072072  | 0.41  | 0.19940029985007496 | 0.2727272727272727  | 0.4166666666666667   |\n",
      "+-------+---------------------+---------------------+-------+---------------------+---------------------+----------------------+\n",
      "| f8(3) | 0.03225806451612903 | 0.4144144144144144  | 0.015 | 0.2353823088455772  | 0.09090909090909091 | 0.2777777777777778   |\n",
      "+-------+---------------------+---------------------+-------+---------------------+---------------------+----------------------+\n",
      "| f8(4) | 0.0967741935483871  | 0.0990990990990991  | 0.03  | 0.17541229385307347 | 0.09090909090909091 | 0.16666666666666666  |\n",
      "+-------+---------------------+---------------------+-------+---------------------+---------------------+----------------------+\n",
      "+-------+-------+-------+----------------------+--------------------+---------------------+-------+---------------------+--------------------+-------+-------+-------+--------------------+\n",
      "| f3    | f3(0) | f3(0) | f3(0)                | f3(0)              | f3(1)               | f3(1) | f3(1)               | f3(1)              | f3(2) | f3(2) | f3(2) | f3(2)              |\n",
      "+-------+-------+-------+----------------------+--------------------+---------------------+-------+---------------------+--------------------+-------+-------+-------+--------------------+\n",
      "| f5    | f5(0) | f5(1) | f5(2)                | f5(3)              | f5(0)               | f5(1) | f5(2)               | f5(3)              | f5(0) | f5(1) | f5(2) | f5(3)              |\n",
      "+-------+-------+-------+----------------------+--------------------+---------------------+-------+---------------------+--------------------+-------+-------+-------+--------------------+\n",
      "| f9(1) | 0.65  | 0.5   | 0.021052631578947368 | 0.3333333333333333 | 0.5179856115107914  | 0.05  | 0.18114874815905743 | 0.2857142857142857 | 0.3   | 0.5   | 0.125 | 0.3333333333333333 |\n",
      "+-------+-------+-------+----------------------+--------------------+---------------------+-------+---------------------+--------------------+-------+-------+-------+--------------------+\n",
      "| f9(2) | 0.35  | 0.5   | 0.9789473684210527   | 0.6666666666666666 | 0.48201438848920863 | 0.95  | 0.8188512518409425  | 0.7142857142857143 | 0.7   | 0.5   | 0.875 | 0.6666666666666666 |\n",
      "+-------+-------+-------+----------------------+--------------------+---------------------+-------+---------------------+--------------------+-------+-------+-------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# Getting model1 cpds\n",
    "print('The cpds obtained using Bayesian Parameter estimation are: \\n')\n",
    "cpds1 = model1.get_cpds()\n",
    "for cpd in cpds1:\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferences using Bayesian Network- \n",
      "Probability of f2:\n",
      "+------+-----------+\n",
      "| f2   |   phi(f2) |\n",
      "+======+===========+\n",
      "| f2_0 |    0.1775 |\n",
      "+------+-----------+\n",
      "| f2_1 |    0.5138 |\n",
      "+------+-----------+\n",
      "| f2_2 |    0.1313 |\n",
      "+------+-----------+\n",
      "| f2_3 |    0.0135 |\n",
      "+------+-----------+\n",
      "| f2_4 |    0.1638 |\n",
      "+------+-----------+\n",
      "\n",
      "Probability f5 given f4=0 and f1=1: \n",
      "+------+-----------+\n",
      "| f5   |   phi(f5) |\n",
      "+======+===========+\n",
      "| f5_0 |    0.1921 |\n",
      "+------+-----------+\n",
      "| f5_1 |    0.0374 |\n",
      "+------+-----------+\n",
      "| f5_2 |    0.7614 |\n",
      "+------+-----------+\n",
      "| f5_3 |    0.0091 |\n",
      "+------+-----------+\n"
     ]
    }
   ],
   "source": [
    "# model 1 is the best among the 3 so using that\n",
    "from pgmpy.inference import VariableElimination\n",
    "infer = VariableElimination(model1)\n",
    "\n",
    "print('Inferences using Bayesian Network- ')\n",
    "print('Probability of f2:')\n",
    "print(infer.query(['f2'])['f2'])\n",
    "\n",
    "print('\\nProbability f5 given f4=0 and f1=1: ')\n",
    "print(infer.query(['f5'], evidence={'f4': 0, 'f1': 1}) ['f5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time for inference using \"Bayesian Network\":  0.04413220001151785\n"
     ]
    }
   ],
   "source": [
    "# Computational time of inference using Bayesian Network\n",
    "import time\n",
    "time_start = time.clock()\n",
    "infer = VariableElimination(model1)\n",
    "infer.query(['f3'])['f3']\n",
    "infer.query(['f2'], evidence={'f1':0, 'f6':1}) ['f2']\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print('Computation time for inference using \"Bayesian Network\": ', time_elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating Markov Model using model1 of Bayesian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferences using Markov Network- \n",
      "Probability of f2:\n",
      "+------+-----------+\n",
      "| f2   |   phi(f2) |\n",
      "+======+===========+\n",
      "| f2_0 |    0.1775 |\n",
      "+------+-----------+\n",
      "| f2_1 |    0.5138 |\n",
      "+------+-----------+\n",
      "| f2_2 |    0.1313 |\n",
      "+------+-----------+\n",
      "| f2_3 |    0.0135 |\n",
      "+------+-----------+\n",
      "| f2_4 |    0.1638 |\n",
      "+------+-----------+\n",
      "\n",
      "Probability f5 given f4=0, f2=1, f3=1, f1=0, f6=1: \n",
      "+------+-----------+\n",
      "| f5   |   phi(f5) |\n",
      "+======+===========+\n",
      "| f5_0 |    0.2424 |\n",
      "+------+-----------+\n",
      "| f5_1 |    0.0293 |\n",
      "+------+-----------+\n",
      "| f5_2 |    0.7215 |\n",
      "+------+-----------+\n",
      "| f5_3 |    0.0068 |\n",
      "+------+-----------+\n"
     ]
    }
   ],
   "source": [
    "mm1 = model1.to_markov_model()\n",
    "mm1.nodes()\n",
    "mm1.edges() \n",
    "\n",
    "# Finding inferences using Markov Network\n",
    "infer = VariableElimination(mm1)\n",
    "\n",
    "print('Inferences using Markov Network- ')\n",
    "print('Probability of f2:')\n",
    "print(infer.query(['f2'])['f2'])\n",
    "\n",
    "print('\\nProbability f5 given f4=0, f2=1, f3=1, f1=0, f6=1: ')\n",
    "print(infer.query(['f5'], evidence={'f2': 1, 'f3': 1, 'f1':0, 'f4':0, 'f6':1}) ['f5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time for inference using \"Markov Network\":  0.037094400002388284\n"
     ]
    }
   ],
   "source": [
    "# Computational time of inference using Bayesian Network\n",
    "import time\n",
    "time_start = time.clock()\n",
    "infer = VariableElimination(mm1)\n",
    "infer.query(['f3'])['f3']\n",
    "infer.query(['f2'], evidence={'f1':0, 'f6':1}) ['f2']\n",
    "time_elapsed = (time.clock() - time_start)\n",
    "print('Computation time for inference using \"Markov Network\": ', time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
